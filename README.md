# Conversation Backend Service

Backend service for the **Associate Engineer â€“ Case Study**.

It exposes REST APIs to:

- Manage **users**, **conversations**, **messages**, and **documents**
- Support two chat modes:
  - **Open chat** â€“ standard LLM conversation
  - **Grounded chat (RAG)** â€“ conversation grounded on uploaded documents
- Handle **conversation history**, **LLM integration**, **basic RAG**, and **cost/context management hooks**

---

## 1. Tech Stack

- **Language**: Python 3.12
- **Framework**: FastAPI
- **DB**: SQLite (via SQLAlchemy)
- **LLM**: Pluggable client, currently a **dummy provider** (no external API needed)
- **Testing**: pytest
- **Containerization**: Docker
- **CI**: GitHub Actions (pytest on each push / PR)

---

## 2. Project Structure

```text
.
â”œâ”€ app/
â”‚  â”œâ”€ api/
â”‚  â”‚  â”œâ”€ conversations.py      # Conversation + message APIs
â”‚  â”‚  â”œâ”€ users.py              # Simple user APIs (create/get)
â”‚  â”‚  â”œâ”€ documents.py          # Document APIs (for RAG)
â”‚  â”‚  â””â”€ schemas.py            # Pydantic models (request/response)
â”‚  â”œâ”€ core/
â”‚  â”‚  â”œâ”€ config.py             # App & env configuration
â”‚  â”‚  â”œâ”€ database.py           # SQLAlchemy engine, session, Base
â”‚  â”‚  â”œâ”€ logging_config.py     # Logging setup
â”‚  â”‚  â””â”€ error_handlers.py     # Global exception handlers
â”‚  â”œâ”€ models/
â”‚  â”‚  â””â”€ models.py             # ORM models (User, Conversation, Message, Document, etc.)
â”‚  â””â”€ services/
â”‚     â”œâ”€ llm_client.py         # LLM client abstraction (dummy provider)
â”‚     â””â”€ context_builder.py    # Conversation history + RAG context builder
â”œâ”€ tests/
â”‚  â”œâ”€ test_health.py           # Health endpoint test
â”‚  â””â”€ test_conversations.py    # Conversation + LLM flow tests
â”œâ”€ docs/
â”‚  â””â”€ ARCHITECTURE.md          # Detailed design / case-study writeup
â”œâ”€ main.py               # FastAPI app entrypoint
â”œâ”€ requirements.txt
â”œâ”€ app.db
â”œâ”€ README.md
â”œâ”€ Dockerfile
â”œâ”€ .gitignore
â”œâ”€ pytest.ini
â””â”€ .env

---

## âš™ 3. Installation & Setup

```bash
git clone https://github.com/nitish120320022/Assignment.git
cd Assignment

conda create -n bot_env python=3.12
conda activate bot_env

pip install -r requirements.txt
```

---

## â–¶ 4. Running the Application

```bash
uvicorn main:app --reload
```

ğŸ”— Swagger UI â†’ http://127.0.0.1:8000/docs  
ğŸ”— Health â†’ http://127.0.0.1:8000/health  

---

# ğŸ”¥ 5. API ROUTES (with JSON Schemas & Examples)

---

### ğŸ§ USER ROUTES

ğŸ“Œ **Create User** â€” `POST /users`

#### Request:
```json
{
  "email": "user@mail.com",
  "full_name": "John Wick"
}
```

#### Response:
```json
{
  "id": 1,
  "email": "user@mail.com",
  "full_name": "John Wick",
  "created_at": "2025-01-01T12:10:00"
}
```

ğŸ“Œ **Get User** â€” `GET /users/{user_id}`

---

### ğŸ“„ DOCUMENT ROUTES (for RAG)

ğŸ“Œ **Upload Document** â€” `POST /documents`

#### Request:
```json
{
  "user_id": 1,
  "name": "Python Guide",
  "source_type": "upload",
  "raw_text": "Python is a programming language..."
}
```

#### Response:
```json
{
  "id": 11,
  "user_id": 1,
  "name": "Python Guide",
  "source_type": "upload",
  "created_at": "2025-01-01T10:22:33"
}
```

ğŸ“Œ **Get All Documents for User** â€” `GET /documents?user_id=1`

ğŸ“Œ **Fetch Single Document** â€” `GET /documents/{document_id}`

---

### ğŸ’¬ CONVERSATION ROUTES

ğŸ“Œ **Create Conversation (with first LLM reply)** â€” `POST /conversations`

#### Request:
```json
{
  "user_id": 1,
  "mode": "grounded",
  "title": "Ask Python",
  "first_message": "What is Python?",
  "document_ids": [11]
}
```

#### Response:
```json
{
  "id": 7,
  "user_id": 1,
  "title": "Ask Python",
  "messages": [
    {"role": "user", "content": "What is Python?"},
    {"role": "assistant", "content": "Python is ... (dummy LLM reply)"}
  ]
}
```

ğŸ“Œ **List Conversations for User** â€”  
`GET /users/{user_id}/conversations?limit=10&offset=0`

ğŸ“Œ **Fetch Full Chat History** â€”  
`GET /conversations/{conversation_id}`

---

### ğŸ—¨ MESSAGE ROUTE

ğŸ“Œ Add Message to Conversation â€” `POST /conversations/{id}/messages`

#### Request:
```json
{
  "content": "Explain Python lists."
}
```

ğŸ“Œ Response (assistant reply is auto-stored):
```json
{
  "role": "user",
  "content": "Explain Python lists."
}
```

---

## ğŸ§ª 6. Testing

```bash
pytest
```

Runs:

| Test | Validates |
|---|---|
| test_health | API readiness |
| test_conversations | Full LLM chat flow |

All tests passing âœ”

---

## ğŸ³ 7. Docker Deployment

```bash
docker build -t conversation-backend .
docker run -p 8000:8000 conversation-backend
```

Then open: http://localhost:8000/docs

---

## ğŸ” 8. GitHub CI Setup

Located at:

```
.github/workflows/ci.yml
```

| Stage | Status |
|---|---|
| Install dependencies | âœ” |
| Run tests | âœ” |
| Validate build | âœ” |

---

## ğŸš€ Future Enhancements

| Upgrade | Value |
|---|---|
| Replace Dummy LLM with OpenAI/Groq/Azure | Real AI responses |
| Vector DB + embeddings | Proper Semantic RAG |
| JWT Auth & Authorization | Secure multi-user access |
| WebSockets | Live chat streaming |
| Token billing UI | Usage cost dashboards |

---

### ğŸ“ Final